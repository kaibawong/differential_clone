{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  Dated Brent  Bonny light  Mars   WTI  Maya Europe  Maya USGC  \\\n",
      "0    1/1/2000         25.5          0.0   0.0   0.0          0.0        0.0   \n",
      "1    1/2/2000         27.9          0.0   0.0   0.0          0.0        0.0   \n",
      "2    1/3/2000         27.3          0.0   0.0   0.0          0.0        0.0   \n",
      "3    1/4/2000         22.6          0.0   0.0   0.0          0.0        0.0   \n",
      "4    1/5/2000         27.6          0.0   0.0   0.0          0.0        0.0   \n",
      "..        ...          ...          ...   ...   ...          ...        ...   \n",
      "231  1/4/2019         71.3          1.4  -2.3  -7.4         -9.8       -6.5   \n",
      "232  1/5/2019         71.1          1.9  -4.3 -10.3        -10.1       -8.4   \n",
      "233  1/6/2019         64.1          1.7  -4.6  -9.4         -8.1       -5.2   \n",
      "234  1/7/2019         64.0          1.4  -2.0  -6.5         -6.9       -4.1   \n",
      "235  1/8/2019         59.0          1.3  -1.9  -4.2        -12.6       -8.0   \n",
      "\n",
      "     ESPO  Urals NWE  Urals MED  ...   FO 0.5%    VGO 2%  Arab light  \\\n",
      "0     0.0       -0.5       -0.5  ...  0.000000  0.276573        1.00   \n",
      "1     0.0       -0.5       -0.5  ...  0.000000  1.195334        0.75   \n",
      "2     0.0       -1.0       -1.5  ...  0.000000  1.038289        0.75   \n",
      "3     0.0       -1.0       -1.4  ...  0.000000 -0.616742        0.75   \n",
      "4     0.0       -0.6       -1.2  ...  0.000000 -1.653571        0.50   \n",
      "..    ...        ...        ...  ...       ...       ...         ...   \n",
      "231   1.7       -0.1        0.4  ... -3.102314  3.919293       -1.90   \n",
      "232   0.5       -0.9       -0.2  ... -5.629664  4.786823       -0.80   \n",
      "233  -0.2       -2.7       -2.5  ... -0.835000  5.262463        0.00   \n",
      "234   2.3       -1.1       -0.5  ...  4.105514  5.853681       -1.10   \n",
      "235   4.2       -0.1        1.2  ... -0.952231  7.948248       -2.70   \n",
      "\n",
      "     Arab Heavy  Azeri BTC  Tapis  Dalia  Oman  Oseberg blend    ORL  \n",
      "0           0.0        0.0    0.2    0.0  -1.3          0.000  0.000  \n",
      "1           0.0        0.0   -0.4    0.0  -2.5          0.000  0.000  \n",
      "2           0.0        0.0    1.2    0.0  -1.6          0.000  0.000  \n",
      "3           0.0        0.0    2.7    0.0   0.1          0.000  0.000  \n",
      "4           0.0        0.0    1.1    0.0  -1.8          0.000  0.000  \n",
      "..          ...        ...    ...    ...   ...            ...    ...  \n",
      "231        -4.4        1.8    3.4    0.6  -0.1          1.080 -5.900  \n",
      "232        -3.5        1.5    2.7    0.1  -1.3          1.522 -5.820  \n",
      "233        -3.0        0.2    2.1   -0.3  -2.3          1.617 -6.375  \n",
      "234        -4.0        1.6    3.8    1.2  -0.3          0.786 -6.990  \n",
      "235        -5.5        2.9    4.4    2.0   0.7          0.683 -6.928  \n",
      "\n",
      "[236 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "combi = pd.read_table('Historical_combi2.csv',delimiter =',')\n",
    "\n",
    "combi=combi.fillna(0)\n",
    "print(combi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#x_train=train_combi[[\"Dated Brent\",\"Jet\",\"ULSD\",\"VGO 2%\"]]\n",
    "\n",
    "X = combi[[\"Dated Brent\",\"Propane\",\"Gasoline\",\"Jet\",\"Gasoil\",\"FO 1%\",\"ULSD\",\"Naphtha\",\"Butane\",\"FO 3.5%\",\"VGO 0.5%\",\n",
    "           \"FO 0.5%\",\"VGO 2%\"]]\n",
    "y = combi[\"Urals NWE\"].values\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "sc= MinMaxScaler()\n",
    "X= sc.fit_transform(X)\n",
    "y= y.reshape(-1,1)\n",
    "y=sc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model and optimiser\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "def build_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=13, input_dim=13))\n",
    "    regressor.add(Dense(10))\n",
    "    regressor.add(Dense(1))\n",
    "    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','accuracy'])\n",
    "    return regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "regressor = KerasRegressor(build_fn=build_regressor, batch_size=32,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "165/165 [==============================] - 0s 908us/step - loss: 455.7265 - mae: 18.2701 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "165/165 [==============================] - 0s 97us/step - loss: 138.8212 - mae: 9.4740 - accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "165/165 [==============================] - 0s 215us/step - loss: 52.5976 - mae: 5.2726 - accuracy: 0.0303\n",
      "Epoch 4/200\n",
      "165/165 [==============================] - 0s 110us/step - loss: 64.0049 - mae: 5.2895 - accuracy: 0.0182\n",
      "Epoch 5/200\n",
      "165/165 [==============================] - 0s 98us/step - loss: 64.9624 - mae: 5.3325 - accuracy: 0.0121\n",
      "Epoch 6/200\n",
      "165/165 [==============================] - 0s 98us/step - loss: 46.9649 - mae: 4.4206 - accuracy: 0.0061\n",
      "Epoch 7/200\n",
      "165/165 [==============================] - 0s 104us/step - loss: 36.4679 - mae: 4.0476 - accuracy: 0.0242\n",
      "Epoch 8/200\n",
      "165/165 [==============================] - 0s 111us/step - loss: 34.2822 - mae: 4.3520 - accuracy: 0.0182\n",
      "Epoch 9/200\n",
      "165/165 [==============================] - 0s 104us/step - loss: 32.6508 - mae: 4.3388 - accuracy: 0.0182\n",
      "Epoch 10/200\n",
      "165/165 [==============================] - 0s 294us/step - loss: 28.9798 - mae: 3.8386 - accuracy: 0.0182\n",
      "Epoch 11/200\n",
      "165/165 [==============================] - 0s 100us/step - loss: 27.0335 - mae: 3.4976 - accuracy: 0.0242\n",
      "Epoch 12/200\n",
      "165/165 [==============================] - 0s 104us/step - loss: 25.6361 - mae: 3.4093 - accuracy: 0.0121\n",
      "Epoch 13/200\n",
      "165/165 [==============================] - 0s 359us/step - loss: 23.4700 - mae: 3.4129 - accuracy: 0.0182\n",
      "Epoch 14/200\n",
      "165/165 [==============================] - 0s 116us/step - loss: 22.3042 - mae: 3.4656 - accuracy: 0.0061\n",
      "Epoch 15/200\n",
      "165/165 [==============================] - 0s 346us/step - loss: 21.2585 - mae: 3.4022 - accuracy: 0.0121\n",
      "Epoch 16/200\n",
      "165/165 [==============================] - 0s 109us/step - loss: 20.1784 - mae: 3.2768 - accuracy: 0.0061\n",
      "Epoch 17/200\n",
      "165/165 [==============================] - 0s 134us/step - loss: 19.2472 - mae: 3.1402 - accuracy: 0.0121\n",
      "Epoch 18/200\n",
      "165/165 [==============================] - 0s 320us/step - loss: 18.4043 - mae: 3.0890 - accuracy: 0.0182\n",
      "Epoch 19/200\n",
      "165/165 [==============================] - 0s 113us/step - loss: 17.4470 - mae: 3.0658 - accuracy: 0.0182\n",
      "Epoch 20/200\n",
      "165/165 [==============================] - 0s 52us/step - loss: 16.7562 - mae: 2.9668 - accuracy: 0.0242\n",
      "Epoch 21/200\n",
      "165/165 [==============================] - 0s 98us/step - loss: 16.0368 - mae: 2.8654 - accuracy: 0.0121\n",
      "Epoch 22/200\n",
      "165/165 [==============================] - 0s 294us/step - loss: 15.1666 - mae: 2.9357 - accuracy: 0.0182\n",
      "Epoch 23/200\n",
      "165/165 [==============================] - 0s 111us/step - loss: 14.5545 - mae: 2.9997 - accuracy: 0.0303\n",
      "Epoch 24/200\n",
      "165/165 [==============================] - 0s 95us/step - loss: 13.7336 - mae: 2.8551 - accuracy: 0.0242\n",
      "Epoch 25/200\n",
      "165/165 [==============================] - 0s 300us/step - loss: 12.8332 - mae: 2.7666 - accuracy: 0.0303\n",
      "Epoch 26/200\n",
      "165/165 [==============================] - 0s 122us/step - loss: 12.2881 - mae: 2.7608 - accuracy: 0.0303\n",
      "Epoch 27/200\n",
      "165/165 [==============================] - 0s 118us/step - loss: 11.6338 - mae: 2.6571 - accuracy: 0.0364\n",
      "Epoch 28/200\n",
      "165/165 [==============================] - 0s 315us/step - loss: 11.0317 - mae: 2.5860 - accuracy: 0.0303\n",
      "Epoch 29/200\n",
      "165/165 [==============================] - 0s 116us/step - loss: 10.6002 - mae: 2.5428 - accuracy: 0.0364\n",
      "Epoch 30/200\n",
      "165/165 [==============================] - 0s 122us/step - loss: 9.9936 - mae: 2.4848 - accuracy: 0.0303\n",
      "Epoch 31/200\n",
      "165/165 [==============================] - 0s 324us/step - loss: 9.6472 - mae: 2.4646 - accuracy: 0.0303\n",
      "Epoch 32/200\n",
      "165/165 [==============================] - 0s 148us/step - loss: 9.0956 - mae: 2.3866 - accuracy: 0.0303\n",
      "Epoch 33/200\n",
      "165/165 [==============================] - 0s 124us/step - loss: 8.6518 - mae: 2.2767 - accuracy: 0.0242\n",
      "Epoch 34/200\n",
      "165/165 [==============================] - 0s 264us/step - loss: 8.3193 - mae: 2.2302 - accuracy: 0.0242\n",
      "Epoch 35/200\n",
      "165/165 [==============================] - 0s 101us/step - loss: 7.9084 - mae: 2.1938 - accuracy: 0.0242\n",
      "Epoch 36/200\n",
      "165/165 [==============================] - 0s 131us/step - loss: 7.6057 - mae: 2.1501 - accuracy: 0.0242\n",
      "Epoch 37/200\n",
      "165/165 [==============================] - 0s 374us/step - loss: 7.3048 - mae: 2.1316 - accuracy: 0.0303\n",
      "Epoch 38/200\n",
      "165/165 [==============================] - 0s 156us/step - loss: 6.9457 - mae: 2.0917 - accuracy: 0.0303\n",
      "Epoch 39/200\n",
      "165/165 [==============================] - 0s 349us/step - loss: 6.6389 - mae: 2.0416 - accuracy: 0.0242\n",
      "Epoch 40/200\n",
      "165/165 [==============================] - 0s 160us/step - loss: 6.3283 - mae: 1.9765 - accuracy: 0.0303\n",
      "Epoch 41/200\n",
      "165/165 [==============================] - 0s 138us/step - loss: 6.1606 - mae: 1.9199 - accuracy: 0.0303\n",
      "Epoch 42/200\n",
      "165/165 [==============================] - 0s 151us/step - loss: 5.8809 - mae: 1.8726 - accuracy: 0.0303\n",
      "Epoch 43/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 5.5893 - mae: 1.8518 - accuracy: 0.0303\n",
      "Epoch 44/200\n",
      "165/165 [==============================] - 0s 320us/step - loss: 5.4124 - mae: 1.8348 - accuracy: 0.0303\n",
      "Epoch 45/200\n",
      "165/165 [==============================] - 0s 142us/step - loss: 5.2228 - mae: 1.8042 - accuracy: 0.0303\n",
      "Epoch 46/200\n",
      "165/165 [==============================] - 0s 151us/step - loss: 4.9822 - mae: 1.7590 - accuracy: 0.0303\n",
      "Epoch 47/200\n",
      "165/165 [==============================] - 0s 345us/step - loss: 4.7838 - mae: 1.7277 - accuracy: 0.0303\n",
      "Epoch 48/200\n",
      "165/165 [==============================] - 0s 100us/step - loss: 4.6287 - mae: 1.7006 - accuracy: 0.0303\n",
      "Epoch 49/200\n",
      "165/165 [==============================] - 0s 95us/step - loss: 4.4942 - mae: 1.6614 - accuracy: 0.0364\n",
      "Epoch 50/200\n",
      "165/165 [==============================] - 0s 99us/step - loss: 4.3035 - mae: 1.6475 - accuracy: 0.0303\n",
      "Epoch 51/200\n",
      "165/165 [==============================] - 0s 101us/step - loss: 4.2417 - mae: 1.6489 - accuracy: 0.0303\n",
      "Epoch 52/200\n",
      "165/165 [==============================] - 0s 97us/step - loss: 4.0165 - mae: 1.5986 - accuracy: 0.0303\n",
      "Epoch 53/200\n",
      "165/165 [==============================] - 0s 95us/step - loss: 3.9091 - mae: 1.5422 - accuracy: 0.0424\n",
      "Epoch 54/200\n",
      "165/165 [==============================] - 0s 88us/step - loss: 3.8060 - mae: 1.5207 - accuracy: 0.0424\n",
      "Epoch 55/200\n",
      "165/165 [==============================] - 0s 255us/step - loss: 3.7305 - mae: 1.5442 - accuracy: 0.0364\n",
      "Epoch 56/200\n",
      "165/165 [==============================] - 0s 96us/step - loss: 3.5495 - mae: 1.4995 - accuracy: 0.0364\n",
      "Epoch 57/200\n",
      "165/165 [==============================] - 0s 104us/step - loss: 3.4358 - mae: 1.4560 - accuracy: 0.0424\n",
      "Epoch 58/200\n",
      "165/165 [==============================] - 0s 96us/step - loss: 3.3673 - mae: 1.4382 - accuracy: 0.0424\n",
      "Epoch 59/200\n",
      "165/165 [==============================] - 0s 249us/step - loss: 3.2253 - mae: 1.4123 - accuracy: 0.0424\n",
      "Epoch 60/200\n",
      "165/165 [==============================] - 0s 105us/step - loss: 3.1089 - mae: 1.3968 - accuracy: 0.0424\n",
      "Epoch 61/200\n",
      "165/165 [==============================] - 0s 129us/step - loss: 3.0227 - mae: 1.3847 - accuracy: 0.0364\n",
      "Epoch 62/200\n",
      "165/165 [==============================] - 0s 120us/step - loss: 2.9087 - mae: 1.3541 - accuracy: 0.0364\n",
      "Epoch 63/200\n",
      "165/165 [==============================] - 0s 100us/step - loss: 2.8659 - mae: 1.3436 - accuracy: 0.0364\n",
      "Epoch 64/200\n",
      "165/165 [==============================] - 0s 101us/step - loss: 2.7571 - mae: 1.3204 - accuracy: 0.0364\n",
      "Epoch 65/200\n",
      "165/165 [==============================] - 0s 269us/step - loss: 2.7129 - mae: 1.3116 - accuracy: 0.0364\n",
      "Epoch 66/200\n",
      "165/165 [==============================] - 0s 108us/step - loss: 2.6146 - mae: 1.2901 - accuracy: 0.0364\n",
      "Epoch 67/200\n",
      "165/165 [==============================] - 0s 112us/step - loss: 2.5743 - mae: 1.2701 - accuracy: 0.0424\n",
      "Epoch 68/200\n",
      "165/165 [==============================] - 0s 275us/step - loss: 2.5074 - mae: 1.2532 - accuracy: 0.0364\n",
      "Epoch 69/200\n",
      "165/165 [==============================] - 0s 107us/step - loss: 2.4256 - mae: 1.2392 - accuracy: 0.0364\n",
      "Epoch 70/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s 100us/step - loss: 2.3708 - mae: 1.2165 - accuracy: 0.0424\n",
      "Epoch 71/200\n",
      "165/165 [==============================] - 0s 114us/step - loss: 2.3104 - mae: 1.2014 - accuracy: 0.0364\n",
      "Epoch 72/200\n",
      "165/165 [==============================] - 0s 252us/step - loss: 2.2486 - mae: 1.1834 - accuracy: 0.0364\n",
      "Epoch 73/200\n",
      "165/165 [==============================] - 0s 106us/step - loss: 2.2035 - mae: 1.1724 - accuracy: 0.0364\n",
      "Epoch 74/200\n",
      "165/165 [==============================] - 0s 117us/step - loss: 2.1761 - mae: 1.1704 - accuracy: 0.0424\n",
      "Epoch 75/200\n",
      "165/165 [==============================] - 0s 281us/step - loss: 2.1076 - mae: 1.1554 - accuracy: 0.0364\n",
      "Epoch 76/200\n",
      "165/165 [==============================] - 0s 114us/step - loss: 2.0681 - mae: 1.1351 - accuracy: 0.0364\n",
      "Epoch 77/200\n",
      "165/165 [==============================] - 0s 101us/step - loss: 2.0150 - mae: 1.1226 - accuracy: 0.0364\n",
      "Epoch 78/200\n",
      "165/165 [==============================] - 0s 96us/step - loss: 1.9709 - mae: 1.1099 - accuracy: 0.0364\n",
      "Epoch 79/200\n",
      "165/165 [==============================] - 0s 115us/step - loss: 1.9560 - mae: 1.0980 - accuracy: 0.0364\n",
      "Epoch 80/200\n",
      "165/165 [==============================] - 0s 105us/step - loss: 1.9151 - mae: 1.0904 - accuracy: 0.0424\n",
      "Epoch 81/200\n",
      "165/165 [==============================] - 0s 102us/step - loss: 1.8585 - mae: 1.0843 - accuracy: 0.0424\n",
      "Epoch 82/200\n",
      "165/165 [==============================] - 0s 274us/step - loss: 1.8013 - mae: 1.0609 - accuracy: 0.0364\n",
      "Epoch 83/200\n",
      "165/165 [==============================] - 0s 107us/step - loss: 1.7868 - mae: 1.0522 - accuracy: 0.0364\n",
      "Epoch 84/200\n",
      "165/165 [==============================] - 0s 90us/step - loss: 1.7456 - mae: 1.0476 - accuracy: 0.0424\n",
      "Epoch 85/200\n",
      "165/165 [==============================] - 0s 272us/step - loss: 1.7147 - mae: 1.0374 - accuracy: 0.0424\n",
      "Epoch 86/200\n",
      "165/165 [==============================] - 0s 126us/step - loss: 1.6924 - mae: 1.0330 - accuracy: 0.0424\n",
      "Epoch 87/200\n",
      "165/165 [==============================] - 0s 104us/step - loss: 1.6856 - mae: 1.0325 - accuracy: 0.0424\n",
      "Epoch 88/200\n",
      "165/165 [==============================] - 0s 99us/step - loss: 1.6159 - mae: 0.9994 - accuracy: 0.0545\n",
      "Epoch 89/200\n",
      "165/165 [==============================] - 0s 249us/step - loss: 1.6305 - mae: 1.0029 - accuracy: 0.0485\n",
      "Epoch 90/200\n",
      "165/165 [==============================] - 0s 96us/step - loss: 1.5874 - mae: 0.9940 - accuracy: 0.0424\n",
      "Epoch 91/200\n",
      "165/165 [==============================] - 0s 100us/step - loss: 1.5430 - mae: 0.9844 - accuracy: 0.0424\n",
      "Epoch 92/200\n",
      "165/165 [==============================] - 0s 296us/step - loss: 1.5205 - mae: 0.9710 - accuracy: 0.0485\n",
      "Epoch 93/200\n",
      "165/165 [==============================] - 0s 98us/step - loss: 1.5532 - mae: 0.9798 - accuracy: 0.0485\n",
      "Epoch 94/200\n",
      "165/165 [==============================] - 0s 102us/step - loss: 1.4523 - mae: 0.9555 - accuracy: 0.0485\n",
      "Epoch 95/200\n",
      "165/165 [==============================] - 0s 96us/step - loss: 1.4679 - mae: 0.9630 - accuracy: 0.0424\n",
      "Epoch 96/200\n",
      "165/165 [==============================] - 0s 274us/step - loss: 1.4483 - mae: 0.9479 - accuracy: 0.0485\n",
      "Epoch 97/200\n",
      "165/165 [==============================] - 0s 91us/step - loss: 1.4171 - mae: 0.9383 - accuracy: 0.0485\n",
      "Epoch 98/200\n",
      "165/165 [==============================] - 0s 101us/step - loss: 1.3900 - mae: 0.9286 - accuracy: 0.0485\n",
      "Epoch 99/200\n",
      "165/165 [==============================] - 0s 305us/step - loss: 1.3842 - mae: 0.9236 - accuracy: 0.0545\n",
      "Epoch 100/200\n",
      "165/165 [==============================] - 0s 101us/step - loss: 1.3601 - mae: 0.9195 - accuracy: 0.0485\n",
      "Epoch 101/200\n",
      "165/165 [==============================] - 0s 105us/step - loss: 1.3966 - mae: 0.9382 - accuracy: 0.0424\n",
      "Epoch 102/200\n",
      "165/165 [==============================] - 0s 101us/step - loss: 1.3081 - mae: 0.9031 - accuracy: 0.0485\n",
      "Epoch 103/200\n",
      "165/165 [==============================] - 0s 113us/step - loss: 1.3365 - mae: 0.9010 - accuracy: 0.0485\n",
      "Epoch 104/200\n",
      "165/165 [==============================] - 0s 101us/step - loss: 1.2799 - mae: 0.8861 - accuracy: 0.0485\n",
      "Epoch 105/200\n",
      "165/165 [==============================] - 0s 95us/step - loss: 1.2876 - mae: 0.8977 - accuracy: 0.0485\n",
      "Epoch 106/200\n",
      "165/165 [==============================] - 0s 255us/step - loss: 1.2738 - mae: 0.8827 - accuracy: 0.0485\n",
      "Epoch 107/200\n",
      "165/165 [==============================] - 0s 95us/step - loss: 1.2402 - mae: 0.8722 - accuracy: 0.0485\n",
      "Epoch 108/200\n",
      "165/165 [==============================] - 0s 95us/step - loss: 1.2203 - mae: 0.8679 - accuracy: 0.0424\n",
      "Epoch 109/200\n",
      "165/165 [==============================] - 0s 96us/step - loss: 1.2160 - mae: 0.8665 - accuracy: 0.0424\n",
      "Epoch 110/200\n",
      "165/165 [==============================] - 0s 279us/step - loss: 1.1961 - mae: 0.8615 - accuracy: 0.0424\n",
      "Epoch 111/200\n",
      "165/165 [==============================] - 0s 93us/step - loss: 1.2067 - mae: 0.8516 - accuracy: 0.0545\n",
      "Epoch 112/200\n",
      "165/165 [==============================] - 0s 90us/step - loss: 1.2306 - mae: 0.8602 - accuracy: 0.0545\n",
      "Epoch 113/200\n",
      "165/165 [==============================] - 0s 94us/step - loss: 1.1963 - mae: 0.8600 - accuracy: 0.0485\n",
      "Epoch 114/200\n",
      "165/165 [==============================] - 0s 279us/step - loss: 1.1865 - mae: 0.8568 - accuracy: 0.0485\n",
      "Epoch 115/200\n",
      "165/165 [==============================] - 0s 103us/step - loss: 1.1411 - mae: 0.8370 - accuracy: 0.0485\n",
      "Epoch 116/200\n",
      "165/165 [==============================] - 0s 95us/step - loss: 1.1299 - mae: 0.8281 - accuracy: 0.0485\n",
      "Epoch 117/200\n",
      "165/165 [==============================] - 0s 270us/step - loss: 1.1190 - mae: 0.8276 - accuracy: 0.0485\n",
      "Epoch 118/200\n",
      "165/165 [==============================] - 0s 96us/step - loss: 1.1118 - mae: 0.8183 - accuracy: 0.0485\n",
      "Epoch 119/200\n",
      "165/165 [==============================] - 0s 90us/step - loss: 1.1069 - mae: 0.8128 - accuracy: 0.0485\n",
      "Epoch 120/200\n",
      "165/165 [==============================] - 0s 91us/step - loss: 1.0969 - mae: 0.8130 - accuracy: 0.0485\n",
      "Epoch 121/200\n",
      "165/165 [==============================] - 0s 268us/step - loss: 1.1263 - mae: 0.8285 - accuracy: 0.0424\n",
      "Epoch 122/200\n",
      "165/165 [==============================] - 0s 92us/step - loss: 1.0911 - mae: 0.8151 - accuracy: 0.0424\n",
      "Epoch 123/200\n",
      "165/165 [==============================] - 0s 92us/step - loss: 1.0601 - mae: 0.7932 - accuracy: 0.0545\n",
      "Epoch 124/200\n",
      "165/165 [==============================] - 0s 107us/step - loss: 1.0763 - mae: 0.7987 - accuracy: 0.0545\n",
      "Epoch 125/200\n",
      "165/165 [==============================] - 0s 270us/step - loss: 1.0521 - mae: 0.7996 - accuracy: 0.0424\n",
      "Epoch 126/200\n",
      "165/165 [==============================] - 0s 99us/step - loss: 1.0562 - mae: 0.7962 - accuracy: 0.0485\n",
      "Epoch 127/200\n",
      "165/165 [==============================] - 0s 98us/step - loss: 1.0680 - mae: 0.7969 - accuracy: 0.0606\n",
      "Epoch 128/200\n",
      "165/165 [==============================] - 0s 94us/step - loss: 1.0525 - mae: 0.7891 - accuracy: 0.0485\n",
      "Epoch 129/200\n",
      "165/165 [==============================] - 0s 98us/step - loss: 1.0581 - mae: 0.7945 - accuracy: 0.0424\n",
      "Epoch 130/200\n",
      "165/165 [==============================] - 0s 93us/step - loss: 1.0012 - mae: 0.7750 - accuracy: 0.0545\n",
      "Epoch 131/200\n",
      "165/165 [==============================] - 0s 91us/step - loss: 0.9915 - mae: 0.7681 - accuracy: 0.0485\n",
      "Epoch 132/200\n",
      "165/165 [==============================] - 0s 287us/step - loss: 1.0050 - mae: 0.7721 - accuracy: 0.0545\n",
      "Epoch 133/200\n",
      "165/165 [==============================] - 0s 98us/step - loss: 0.9781 - mae: 0.7622 - accuracy: 0.0545\n",
      "Epoch 134/200\n",
      "165/165 [==============================] - 0s 94us/step - loss: 0.9707 - mae: 0.7580 - accuracy: 0.0485\n",
      "Epoch 135/200\n",
      "165/165 [==============================] - 0s 140us/step - loss: 0.9991 - mae: 0.7697 - accuracy: 0.0667\n",
      "Epoch 136/200\n",
      "165/165 [==============================] - 0s 233us/step - loss: 0.9590 - mae: 0.7520 - accuracy: 0.0545\n",
      "Epoch 137/200\n",
      "165/165 [==============================] - 0s 97us/step - loss: 0.9709 - mae: 0.7575 - accuracy: 0.0545\n",
      "Epoch 138/200\n",
      "165/165 [==============================] - 0s 95us/step - loss: 0.9523 - mae: 0.7502 - accuracy: 0.0485\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165/165 [==============================] - 0s 313us/step - loss: 0.9378 - mae: 0.7440 - accuracy: 0.0485\n",
      "Epoch 140/200\n",
      "165/165 [==============================] - 0s 73us/step - loss: 0.9381 - mae: 0.7434 - accuracy: 0.0545\n",
      "Epoch 141/200\n",
      "165/165 [==============================] - 0s 64us/step - loss: 0.9265 - mae: 0.7378 - accuracy: 0.0545\n",
      "Epoch 142/200\n",
      "165/165 [==============================] - 0s 86us/step - loss: 0.9208 - mae: 0.7337 - accuracy: 0.0485\n",
      "Epoch 143/200\n",
      "165/165 [==============================] - 0s 278us/step - loss: 0.9202 - mae: 0.7316 - accuracy: 0.0606\n",
      "Epoch 144/200\n",
      "165/165 [==============================] - 0s 104us/step - loss: 0.9097 - mae: 0.7303 - accuracy: 0.0667\n",
      "Epoch 145/200\n",
      "165/165 [==============================] - 0s 100us/step - loss: 0.9232 - mae: 0.7317 - accuracy: 0.0485\n",
      "Epoch 146/200\n",
      "165/165 [==============================] - 0s 104us/step - loss: 0.8992 - mae: 0.7273 - accuracy: 0.0606\n",
      "Epoch 147/200\n",
      "165/165 [==============================] - 0s 275us/step - loss: 0.9073 - mae: 0.7289 - accuracy: 0.0667\n",
      "Epoch 148/200\n",
      "165/165 [==============================] - 0s 110us/step - loss: 0.9082 - mae: 0.7287 - accuracy: 0.0667\n",
      "Epoch 149/200\n",
      "165/165 [==============================] - 0s 107us/step - loss: 0.8998 - mae: 0.7213 - accuracy: 0.0667\n",
      "Epoch 150/200\n",
      "165/165 [==============================] - 0s 272us/step - loss: 0.8868 - mae: 0.7159 - accuracy: 0.0545\n",
      "Epoch 151/200\n",
      "165/165 [==============================] - 0s 106us/step - loss: 0.8848 - mae: 0.7151 - accuracy: 0.0485\n",
      "Epoch 152/200\n",
      "165/165 [==============================] - 0s 95us/step - loss: 0.8820 - mae: 0.7137 - accuracy: 0.0485\n",
      "Epoch 153/200\n",
      "165/165 [==============================] - 0s 96us/step - loss: 0.8725 - mae: 0.7104 - accuracy: 0.0545\n",
      "Epoch 154/200\n",
      "165/165 [==============================] - 0s 244us/step - loss: 0.9043 - mae: 0.7243 - accuracy: 0.0667\n",
      "Epoch 155/200\n",
      "165/165 [==============================] - 0s 110us/step - loss: 0.8775 - mae: 0.7171 - accuracy: 0.0667\n",
      "Epoch 156/200\n",
      "165/165 [==============================] - 0s 100us/step - loss: 0.8992 - mae: 0.7147 - accuracy: 0.0606\n",
      "Epoch 157/200\n",
      "165/165 [==============================] - 0s 267us/step - loss: 0.8966 - mae: 0.7102 - accuracy: 0.0667\n",
      "Epoch 158/200\n",
      "165/165 [==============================] - 0s 110us/step - loss: 0.9114 - mae: 0.7290 - accuracy: 0.0667\n",
      "Epoch 159/200\n",
      "165/165 [==============================] - 0s 113us/step - loss: 0.8599 - mae: 0.6998 - accuracy: 0.0606\n",
      "Epoch 160/200\n",
      "165/165 [==============================] - 0s 98us/step - loss: 0.8525 - mae: 0.7015 - accuracy: 0.0545\n",
      "Epoch 161/200\n",
      "165/165 [==============================] - 0s 258us/step - loss: 0.8382 - mae: 0.6939 - accuracy: 0.0667\n",
      "Epoch 162/200\n",
      "165/165 [==============================] - 0s 114us/step - loss: 0.8400 - mae: 0.6952 - accuracy: 0.0667\n",
      "Epoch 163/200\n",
      "165/165 [==============================] - 0s 139us/step - loss: 0.8417 - mae: 0.6887 - accuracy: 0.0727\n",
      "Epoch 164/200\n",
      "165/165 [==============================] - 0s 280us/step - loss: 0.8465 - mae: 0.6993 - accuracy: 0.0727\n",
      "Epoch 165/200\n",
      "165/165 [==============================] - 0s 150us/step - loss: 0.8265 - mae: 0.6872 - accuracy: 0.0667\n",
      "Epoch 166/200\n",
      "165/165 [==============================] - 0s 128us/step - loss: 0.8213 - mae: 0.6849 - accuracy: 0.0667\n",
      "Epoch 167/200\n",
      "165/165 [==============================] - 1s 6ms/step - loss: 0.8249 - mae: 0.6877 - accuracy: 0.0667\n",
      "Epoch 168/200\n",
      "165/165 [==============================] - 0s 73us/step - loss: 0.8358 - mae: 0.6883 - accuracy: 0.0727\n",
      "Epoch 169/200\n",
      "165/165 [==============================] - 0s 94us/step - loss: 0.8350 - mae: 0.6911 - accuracy: 0.0667\n",
      "Epoch 170/200\n",
      "165/165 [==============================] - 0s 101us/step - loss: 0.8103 - mae: 0.6784 - accuracy: 0.0667\n",
      "Epoch 171/200\n",
      "165/165 [==============================] - 0s 97us/step - loss: 0.8217 - mae: 0.6845 - accuracy: 0.0727\n",
      "Epoch 172/200\n",
      "165/165 [==============================] - 0s 94us/step - loss: 0.8247 - mae: 0.6847 - accuracy: 0.0667\n",
      "Epoch 173/200\n",
      "165/165 [==============================] - 0s 247us/step - loss: 0.8054 - mae: 0.6771 - accuracy: 0.0727\n",
      "Epoch 174/200\n",
      "165/165 [==============================] - 0s 113us/step - loss: 0.8072 - mae: 0.6791 - accuracy: 0.0667\n",
      "Epoch 175/200\n",
      "165/165 [==============================] - 0s 123us/step - loss: 0.7963 - mae: 0.6680 - accuracy: 0.0727\n",
      "Epoch 176/200\n",
      "165/165 [==============================] - 0s 286us/step - loss: 0.8129 - mae: 0.6768 - accuracy: 0.0788\n",
      "Epoch 177/200\n",
      "165/165 [==============================] - 0s 126us/step - loss: 0.7951 - mae: 0.6664 - accuracy: 0.0727\n",
      "Epoch 178/200\n",
      "165/165 [==============================] - 0s 102us/step - loss: 0.8198 - mae: 0.6739 - accuracy: 0.0667\n",
      "Epoch 179/200\n",
      "165/165 [==============================] - 0s 292us/step - loss: 0.7912 - mae: 0.6676 - accuracy: 0.0667\n",
      "Epoch 180/200\n",
      "165/165 [==============================] - 0s 112us/step - loss: 0.8474 - mae: 0.6833 - accuracy: 0.0727\n",
      "Epoch 181/200\n",
      "165/165 [==============================] - 0s 113us/step - loss: 0.8110 - mae: 0.6729 - accuracy: 0.0727\n",
      "Epoch 182/200\n",
      "165/165 [==============================] - 0s 104us/step - loss: 0.7932 - mae: 0.6731 - accuracy: 0.0727\n",
      "Epoch 183/200\n",
      "165/165 [==============================] - 0s 289us/step - loss: 0.7751 - mae: 0.6602 - accuracy: 0.0788\n",
      "Epoch 184/200\n",
      "165/165 [==============================] - 0s 107us/step - loss: 0.7778 - mae: 0.6550 - accuracy: 0.0727\n",
      "Epoch 185/200\n",
      "165/165 [==============================] - 0s 90us/step - loss: 0.7733 - mae: 0.6577 - accuracy: 0.0788\n",
      "Epoch 186/200\n",
      "165/165 [==============================] - 0s 297us/step - loss: 0.7801 - mae: 0.6482 - accuracy: 0.0788\n",
      "Epoch 187/200\n",
      "165/165 [==============================] - 0s 107us/step - loss: 0.7659 - mae: 0.6582 - accuracy: 0.0788\n",
      "Epoch 188/200\n",
      "165/165 [==============================] - 0s 98us/step - loss: 0.8017 - mae: 0.6749 - accuracy: 0.0727\n",
      "Epoch 189/200\n",
      "165/165 [==============================] - 0s 94us/step - loss: 0.7699 - mae: 0.6496 - accuracy: 0.0727\n",
      "Epoch 190/200\n",
      "165/165 [==============================] - 0s 249us/step - loss: 0.7510 - mae: 0.6484 - accuracy: 0.0727\n",
      "Epoch 191/200\n",
      "165/165 [==============================] - 0s 115us/step - loss: 0.7774 - mae: 0.6681 - accuracy: 0.0727\n",
      "Epoch 192/200\n",
      "165/165 [==============================] - 0s 109us/step - loss: 0.8097 - mae: 0.6650 - accuracy: 0.0788\n",
      "Epoch 193/200\n",
      "165/165 [==============================] - 0s 297us/step - loss: 0.7711 - mae: 0.6643 - accuracy: 0.0727\n",
      "Epoch 194/200\n",
      "165/165 [==============================] - 0s 105us/step - loss: 0.8510 - mae: 0.7058 - accuracy: 0.0727\n",
      "Epoch 195/200\n",
      "165/165 [==============================] - 0s 104us/step - loss: 0.7782 - mae: 0.6581 - accuracy: 0.0788\n",
      "Epoch 196/200\n",
      "165/165 [==============================] - 0s 99us/step - loss: 0.7445 - mae: 0.6404 - accuracy: 0.0788\n",
      "Epoch 197/200\n",
      "165/165 [==============================] - 0s 117us/step - loss: 0.7502 - mae: 0.6533 - accuracy: 0.0788\n",
      "Epoch 198/200\n",
      "165/165 [==============================] - 0s 112us/step - loss: 0.7340 - mae: 0.6395 - accuracy: 0.0788\n",
      "Epoch 199/200\n",
      "165/165 [==============================] - 0s 112us/step - loss: 0.7410 - mae: 0.6383 - accuracy: 0.0788\n",
      "Epoch 200/200\n",
      "165/165 [==============================] - 0s 251us/step - loss: 0.7377 - mae: 0.6381 - accuracy: 0.0788\n"
     ]
    }
   ],
   "source": [
    "results=regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, y_pred)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
